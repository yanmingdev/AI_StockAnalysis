# -*- coding: utf-8 -*-
"""
AI Stock Analyzer | å°è‚¡ ï¼ˆç²¾ç°¡ç‰ˆï¼šç§»é™¤é ç±¤ï¼äº¤æ˜“åˆ†é ã€æ–°èå›ºå®šé–‹å•Ÿã€ç§»é™¤å¸‚å ´æƒ…ç·’ç¸½çµé¡¯ç¤ºï¼‰
"""
import os, re, io, json, datetime as dt
from pathlib import Path
from urllib.parse import quote_plus
import xml.etree.ElementTree as ET

import requests
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from dotenv import load_dotenv
from google import genai
from google.genai import types

# æŠ€è¡“æŒ‡æ¨™
from ta.trend import SMAIndicator, MACD
from ta.momentum import RSIIndicator, StochasticOscillator
from ta.volatility import BollingerBands

# ====== å¸¸æ•¸ï¼ˆç²¾ç°¡ UI ç‰ˆæœ¬çš„å›ºå®šåƒæ•¸ï¼‰======
NEWS_ITEM_MAX_CHARS = 1200
CACHE_TTL_SEC = 900
GEMINI_MODEL = "gemini-1.5-flash"
VOLUME_LOOKBACK = 30
VOL_SPIKE_MULTIPLIER = 1.5

# å›ºå®šåœ–è³‡æœŸé–“èˆ‡æŠ€è¡“è¦–çª—
DEFAULT_PERIOD = "1y"
DEFAULT_INTERVAL = "1d"
DEFAULT_LOOKBACK = 30  # è¿‘ N æ ¹

# å›ºå®š AI æº«åº¦ï¼ˆè¼ƒè©³ç´°ã€è¼ƒä¸€è‡´ï¼‰
FIXED_TEMPERATURE = 0.2

# ====== ç‰ˆé¢èˆ‡æ¨£å¼ ======
st.set_page_config(page_title="AI å¸‚å ´æƒ…å ±åˆ†æåŠ©ç†ï¼ˆå°è‚¡ï¼‰", page_icon="ğŸ“Š", layout="wide")

st.markdown("""
<style>
/* å›ºå®šå´æ¬„å¯¬åº¦ */
section[data-testid="stSidebar"] { width: 300px !important; }

/* éš±è— Streamlit é è¨­çš„å¤šé å°è¦½ï¼ˆæœƒé¡¯ç¤º stock analyzer / tradingï¼‰ */
div[data-testid="stSidebarNav"] { display: none !important; }

/* Topbar */
.topbar { position: sticky; top: 0; z-index: 999; backdrop-filter: blur(6px);
  background: rgba(16,16,20,.78); border-bottom: 1px solid rgba(255,255,255,.08);
  margin: -1rem -1rem 12px -1rem; padding: 10px 16px; }
.topbar .wrap { display: flex; align-items: center; gap: 14px; flex-wrap: wrap; }
.topbar a { text-decoration: none; font-weight: 600; font-size: 14px; padding: 6px 10px;
  border-radius: 8px; border: 1px solid rgba(255,255,255,.08); }
.topbar a:hover { background: rgba(255,255,255,.06); }
.topbar .spacer { flex: 1; }

.header-title { font-size:26px; font-weight:800; margin: 6px 0 4px 0; }
.header-sub   { color:#aaa; margin: 0 0 12px 0; }

.card { border:1px solid #2b2f36; border-radius:12px; padding:14px; margin:10px 0;
  background:#111; box-shadow: 0 1px 2px rgba(0,0,0,.08); }
.badge { display:inline-block; padding:2px 8px; border-radius:999px; font-size:12px; margin-right:6px; }
.badge-green{ background:#0f5132; color:#b6ffce;}
.badge-red  { background:#5c1b1b; color:#ffc4c4;}
.badge-gray { background:#2f3640; color:#dfe6e9;}
.small { color:#aaa; font-size:12px; }
</style>

<div class="topbar">
  <div class="wrap">
    <span>ğŸ§­ å¿«é€Ÿå°è¦½ï¼š</span>
    <a href="#sec-chart">è‚¡åƒ¹åœ–</a>
    <a href="#sec-tech">æŠ€è¡“æŒ‡æ¨™</a>
    <a href="#sec-news">æƒ…å ±æ–°è</a>
    <!-- å·²ç§»é™¤ã€Œå¸‚å ´æƒ…ç·’ç¸½çµã€èˆ‡ã€Œäº¤æ˜“ç´€éŒ„ï¼å ±é…¬ã€é€£çµ -->
    <a href="#sec-ai">AI åˆ†æçµæœ</a>
    <span class="spacer"></span>
  </div>
</div>
""", unsafe_allow_html=True)

st.markdown('<div class="header-title">AI Stock Analyzer | AI å¸‚å ´æƒ…å ±åˆ†æåŠ©ç†ï¼ˆå°è‚¡ï¼‰</div>', unsafe_allow_html=True)
st.markdown('<div class="header-sub">è³‡è¨Šæ•´åˆ ï½œ è‡ªå‹•åˆ†æ ï½œ æ±ºç­–è¼”åŠ©ï¼ˆä¸æä¾›æŠ•è³‡å»ºè­°ï¼‰</div>', unsafe_allow_html=True)

# ====== ENV / Gemini ======
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY") or st.secrets.get("GEMINI_API_KEY", None)
if not API_KEY:
    st.error("âŒ æ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹åœ¨ .env æˆ– st.secrets è¨­å®šã€‚")
    st.stop()

@st.cache_resource(show_spinner=False)
def get_gemini_client(api_key: str):
    return genai.Client(api_key=api_key)
client = get_gemini_client(API_KEY)

# ====== Session ======
if "last_params" not in st.session_state:
    st.session_state.last_params = None

# ====== å°å·¥å…· ======
def _s(obj, default=""): return str(obj) if obj is not None else default

def _epoch_to_local_str(sec: int) -> str:
    """epoch -> æœ¬æ©Ÿæ™‚å€ YYYY/MM/DD HH:MM"""
    try:
        return dt.datetime.fromtimestamp(int(sec)).strftime("%Y/%m/%d %H:%M")
    except Exception:
        return ""

def _fmt_dt_str(s: str) -> str:
    """RFC822/å¸¸è¦‹å­—ä¸² -> æœ¬æ©Ÿæ™‚å€ YYYY/MM/DD HH:MMï¼›å¤±æ•—å›ç©ºå­—ä¸²"""
    if not s:
        return ""
    for fmt in [
        "%a, %d %b %Y %H:%M:%S %Z",
        "%a, %d %b %Y %H:%M:%S %z",
        "%Y-%m-%d %H:%M:%S",
        "%Y/%m/%d %H:%M",
    ]:
        try:
            d = dt.datetime.strptime(s.strip(), fmt)
            if d.tzinfo:
                return d.astimezone().strftime("%Y/%m/%d %H:%M")
            return d.strftime("%Y/%m/%d %H:%M")
        except Exception:
            continue
    return ""

def to_text(x) -> str:
    if x is None: return ""
    if isinstance(x, str): return x
    if isinstance(x, (int, float, np.number)): return str(x)
    if isinstance(x, (list, tuple, set)): return "ï¼›".join(to_text(i) for i in list(x)[:8])
    if isinstance(x, dict):
        if "content" in x and isinstance(x["content"], str): return x["content"]
        if "summary" in x and isinstance(x["summary"], str): return x["summary"]
        try: return "ï¼›".join(f"{k}:{to_text(v)}" for k, v in list(x.items())[:6])
        except Exception: return json.dumps(x, ensure_ascii=False)
    return str(x)

def get_series(df: pd.DataFrame, col: str) -> pd.Series:
    if isinstance(df.columns, pd.MultiIndex):
        if col in df.columns.get_level_values(0):
            s = df[col]
        else:
            match = [c for c in df.columns if isinstance(c, tuple) and c[0] == col]
            s = df[match[0]] if match else df.iloc[:, 0]
    else:
        s = df[col] if col in df.columns else df.iloc[:, 0]
    if isinstance(s, pd.DataFrame): s = s.iloc[:, 0]
    return pd.to_numeric(s.squeeze(), errors="coerce")

# ====== å–åƒ¹ / æœå°‹ï¼ˆå¼·åŒ–ï¼‰ ======
@st.cache_data(show_spinner=False, ttl=CACHE_TTL_SEC)
def fetch_ohlcv(sym: str, per: str, itv: str) -> pd.DataFrame:
    return yf.download(sym, period=per, interval=itv, auto_adjust=False, progress=False)

@st.cache_data(ttl=600, show_spinner=False)
def _verify_symbol_has_data(symbol: str) -> bool:
    """ç”¨çŸ­æœŸè³‡æ–™é©—è­‰ä»£è™Ÿæ˜¯å¦å­˜åœ¨ï¼ˆè‚¡ç¥¨/ETF/æ¬Šè­‰çš†å¯ï¼‰ã€‚"""
    try:
        df = yf.download(symbol, period="5d", interval="1d", progress=False)
        return not df.empty
    except Exception:
        return False

@st.cache_data(ttl=3600, show_spinner=False)
def yahoo_search_tw(query: str, max_items: int = 20) -> list[dict]:
    """Yahoo API æ¨¡ç³Šæœå°‹ï¼ˆå…¬å¸å/ä»£è™Ÿï¼‰ï¼Œåªå›å‚³ .TW/.TWOã€‚"""
    if not query or len(query.strip()) < 1: return []
    url = "https://query1.finance.yahoo.com/v1/finance/search"
    params = {"q": query.strip(), "lang": "zh-TW", "region": "TW"}
    try:
        data = requests.get(url, params=params, timeout=7).json() or {}
    except Exception:
        return []
    out = []
    for it in (data.get("quotes") or []):
        sym = (it.get("symbol") or "").strip()
        name = it.get("shortname") or it.get("longname") or it.get("name") or ""
        if sym.endswith(".TW") or sym.endswith(".TWO"):
            out.append({"symbol": sym, "name": name})
    # å»é‡
    uniq, seen = [], set()
    for x in out:
        if x["symbol"] not in seen:
            uniq.append(x); seen.add(x["symbol"])
    return uniq[:max_items]

@st.cache_data(ttl=1800, show_spinner=False)
def _resolve_numeric_code_candidates(code: str) -> list[dict]:
    """
    ç´”æ•¸å­—ï¼ˆ4~6 ç¢¼ï¼‰â†’ ä¾åºå˜—è©¦ .TW / .TWOï¼Œé©—è­‰æœ‰åƒ¹é‡å°±æ”¶éŒ„ï¼Œé©ç”¨è‚¡ç¥¨ / ETF / æ¬Šè­‰ã€‚
    ä¾‹ï¼š1815 â†’ 1815.TW æˆ– 1815.TWOï¼›0050 â†’ 0050.TWï¼ˆETFï¼‰ã€‚
    """
    code = code.strip()
    if not re.fullmatch(r"\d{4,6}", code):
        return []
    candidates = []
    for mkt in (".TW", ".TWO"):
        sym = f"{code}{mkt}"
        if _verify_symbol_has_data(sym):
            # å–åç¨±ï¼ˆå¤±æ•—å°±ç©ºå­—ä¸²ï¼Œä¸å½±éŸ¿é¡¯ç¤ºï¼‰
            try:
                info = yf.Ticker(sym).info or {}
                nm = info.get("longName") or info.get("shortName") or ""
            except Exception:
                nm = ""
            candidates.append({"symbol": sym, "name": nm})
    return candidates

@st.cache_data(ttl=3600, show_spinner=False)
def get_name_by_symbol(symbol: str) -> str:
    """å„ªå…ˆç”¨ Yahoo æœå°‹çµæœåç¨±ï¼›å¦å‰‡å›é€€ yfinance çš„ info åç¨±ï¼›å†ä¸è¡Œå°±ç©ºå­—ä¸²ã€‚"""
    if not symbol: return ""
    try:
        info = yf.Ticker(symbol).info or {}
        nm = info.get("longName") or info.get("shortName") or ""
        if nm: return nm
    except Exception:
        pass
    res = yahoo_search_tw(symbol, 5)
    for it in res:
        if it["symbol"].upper() == symbol.upper():
            return it["name"] or ""
    return ""

# ====== æŒ‡æ¨™è¨ˆç®— ======
def compute_indicators(raw: pd.DataFrame) -> pd.DataFrame:
    df = raw.copy()
    open_s  = get_series(df, "Open")
    high_s  = get_series(df, "High")
    low_s   = get_series(df, "Low")
    close_s = get_series(df, "Close")
    vol_s   = get_series(df, "Volume").fillna(0)
    df = pd.DataFrame({
        "Open": open_s.values, "High": high_s.values, "Low": low_s.values,
        "Close": close_s.values, "Volume": vol_s.values
    }, index=raw.index)

    df["SMA20"] = SMAIndicator(close=close_s, window=20, fillna=False).sma_indicator()
    df["SMA60"] = SMAIndicator(close=close_s, window=60, fillna=False).sma_indicator()

    macd = MACD(close=close_s, window_slow=26, window_fast=12, window_sign=9, fillna=False)
    df["MACD"], df["MACD_signal"], df["MACD_hist"] = macd.macd(), macd.macd_signal(), macd.macd_diff()

    df["RSI14"] = RSIIndicator(close=close_s, window=14, fillna=False).rsi()

    bb = BollingerBands(close=close_s, window=20, window_dev=2, fillna=False)
    df["BB_low"], df["BB_mid"], df["BB_high"] = bb.bollinger_lband(), bb.bollinger_mavg(), bb.bollinger_hband()

    stoch = StochasticOscillator(high=high_s, low=low_s, close=close_s, window=9, smooth_window=3, fillna=False)
    df["KD_K"], df["KD_D"] = stoch.stoch(), stoch.stoch_signal()
    return df

# ===== ç°¡æ˜“é æ¸¬ï¼ˆä¿ç•™ï¼‰ =====
def compute_atr(df: pd.DataFrame, window: int = 14) -> float:
    high, low, close = df["High"], df["Low"], df["Close"]
    prev_close = close.shift(1)
    tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)
    atr = tr.rolling(window).mean()
    last_atr = float(atr.iloc[-1]) if not np.isnan(atr.iloc[-1]) else float(close.iloc[-1] * 0.01)
    return max(last_atr, 0.0001)

def next_period_index(last_index: pd.Timestamp, steps: int, interval: str) -> list[pd.Timestamp]:
    idx, t = [], pd.Timestamp(last_index)
    if interval == "1wk":
        for i in range(1, steps + 1): idx.append(t + pd.Timedelta(weeks=i))
    else:
        d = t
        while len(idx) < steps:
            d = d + pd.Timedelta(days=1)
            if d.weekday() < 5: idx.append(d)
    return idx

def forecast_ohlc(df: pd.DataFrame, steps: int, interval: str = "1d"):
    close = df["Close"].dropna()
    ret = np.log(close).diff().dropna()
    use_n = min(max(60, 30), len(ret)) or len(ret)
    mu, sigma = float(ret.tail(use_n).mean()), float(ret.tail(use_n).std(ddof=0) or 0.0)
    last_close = float(close.iloc[-1])
    atr = compute_atr(df, window=14)
    f_idx = next_period_index(df.index[-1], steps, interval)

    opens, highs, lows, closes_med, p10_list, p90_list = [], [], [], [], [], []
    prev_close = last_close
    for s, ts in enumerate(f_idx, start=1):
        med = last_close * np.exp(mu * s)
        z = 1.2816
        p10 = last_close * np.exp(mu * s - z * sigma * np.sqrt(s))
        p90 = last_close * np.exp(mu * s + z * sigma * np.sqrt(s))
        o = prev_close
        delta = med - o
        hi = max(o, med) + 0.6 * atr + max(delta, 0) * 0.25
        lo = min(o, med) - 0.6 * atr + min(delta, 0) * 0.25
        opens.append(o); highs.append(hi); lows.append(lo); closes_med.append(med)
        p10_list.append(p10); p90_list.append(p90)
        prev_close = med

    fdf = pd.DataFrame({"Open": opens, "High": highs, "Low": lows, "Close": closes_med},
                       index=pd.DatetimeIndex(f_idx, name=df.index.name))
    med = pd.Series(closes_med, index=fdf.index); p10 = pd.Series(p10_list, index=fdf.index); p90 = pd.Series(p90_list, index=fdf.index)
    return fdf, med, p10, p90

# ====== Fibonacciï¼ˆæ­£ï¼è²  38.2% èˆ‡ 61.8%ï¼Œåªè¼¸å‡ºè¡¨æ ¼ï¼‰ ======
def compute_fib_posneg(df: pd.DataFrame, lookback: int) -> pd.DataFrame:
    """ä»¥è¿‘ N æ ¹é«˜ä½çš„æŒ¯å¹… Rï¼Œæ¨ç´ P=æœ€æ–°æ”¶ç›¤ï¼Œè¼¸å‡º Â±38.2%ã€Â±61.8% åƒ¹ä½ã€‚"""
    tail = df.dropna().tail(lookback)
    if tail.empty:
        return pd.DataFrame()
    high = float(tail["High"].max())
    low  = float(tail["Low"].min())
    if not np.isfinite(high) or not np.isfinite(low) or high == low:
        return pd.DataFrame()
    rng = high - low
    P = float(tail["Close"].iloc[-1])
    levels = [
        ("-61.8%", round(P - 0.618*rng, 2)),
        ("-38.2%", round(P - 0.382*rng, 2)),
        ("+38.2%", round(P + 0.382*rng, 2)),
        ("+61.8%", round(P + 0.618*rng, 2)),
    ]
    df_levels = pd.DataFrame(levels, columns=["å±¤ç´š", "åƒ¹ä½"])
    return df_levels

def summarize_features(df: pd.DataFrame, lookback: int) -> dict:
    """æŠ€è¡“æ‘˜è¦ï¼šæ¼²è·Œå¹…/å‡ç·š/RSI/KD/MACD/é‡èƒ½ï¼Œä¸¦ä»¥ 0.618(ä¸‹)/0.382(ä¸Š) åšæ”¯æ’/å£“åŠ›æç¤ºã€‚"""
    tail = df.dropna().tail(max(lookback, VOLUME_LOOKBACK)).copy()
    last, first = tail.iloc[-1], tail.iloc[0]
    pct_change = round((last["Close"]/first["Close"]-1)*100, 2)
    ma_trend = "å¤šé ­" if last["SMA20"] > last["SMA60"] else "ç©ºé ­"
    golden_cross = bool((tail["SMA20"].iloc[-2] <= tail["SMA60"].iloc[-2]) and (last["SMA20"] > last["SMA60"]))
    dead_cross   = bool((tail["SMA20"].iloc[-2] >= tail["SMA60"].iloc[-2]) and (last["SMA20"] < last["SMA60"]))
    rsi_state = "è¶…è²·(>70)" if last["RSI14"] >= 70 else ("è¶…è³£(<30)" if last["RSI14"] <= 30 else "ä¸­æ€§")
    vol_tail = tail["Volume"].tail(VOLUME_LOOKBACK)
    vol_mean = float(vol_tail.mean())
    vol_spike = bool(last["Volume"] >= VOL_SPIKE_MULTIPLIER * vol_mean)
    # æ”¯æ’/å£“åŠ›ï¼ˆretracement åƒè€ƒï¼‰
    high = float(tail["High"].max()); low = float(tail["Low"].min()); diff = high - low
    support = round(high - 0.618*diff, 2)
    resistance = round(high - 0.382*diff, 2)

    return {
        "as_of": str(tail.index[-1].date()),
        "period_bars": lookback,
        "close_last": round(float(last["Close"]), 2),
        "pct_change_period": pct_change,
        "ma_trend": ma_trend, "golden_cross": golden_cross, "dead_cross": dead_cross,
        "rsi14": round(float(last["RSI14"]), 2) if pd.notna(last["RSI14"]) else None,
        "rsi_state": rsi_state,
        "volume_last": int(last["Volume"]), "volume_mean_period": int(vol_mean), "volume_spike": vol_spike,
        "support_near": support, "resistance_near": resistance,
        "kd_k": round(float(last.get("KD_K", float('nan'))), 2) if pd.notna(last.get("KD_K", None)) else None,
        "kd_d": round(float(last.get("KD_D", float('nan'))), 2) if pd.notna(last.get("KD_D", None)) else None,
        "macd": round(float(last.get("MACD", float('nan'))), 4) if pd.notna(last.get("MACD", None)) else None,
        "macd_signal": round(float(last.get("MACD_signal", float('nan'))), 4) if pd.notna(last.get("MACD_signal", None)) else None,
        "macd_hist": round(float(last.get("MACD_hist", float('nan'))), 4) if pd.notna(last.get("MACD_hist", None)) else None
    }

# ===== æ–‡å­—/æ–°èï¼AI å ±å‘Š =====
def load_prompt(path: str, fallback: str) -> str:
    p = Path(path)
    if p.exists():
        try: return p.read_text(encoding="utf-8")
        except Exception: pass
    return fallback

def extract_json_block(text: str):
    if not text: return None
    m = re.search(r'```json\s*(\[[\s\S]*?\])\s*```', text) or re.search(r'(\[[\s\S]*\])', text)
    if m:
        try: return json.loads(m.group(1))
        except Exception: pass
    m2 = re.search(r'```json\s*({[\s\S]*?})\s*```', text) or re.search(r'({[\s\S]*})', text)
    if m2:
        try: return json.loads(m2.group(1))
        except Exception: pass
    try: return json.loads(text)
    except Exception: return None

# --- Yahoo Finance æ–°èï¼ˆå·²ä¿®æ­£ï¼šåˆ‡ç‰‡å‰è½‰å­—ä¸²ï¼‰ ---
@st.cache_data(show_spinner=False, ttl=600)
def fetch_news_yahoo(symbol: str, max_items: int = 3):
    """
    å¾ yfinance å–æ–°èã€‚yfinance æŸäº›æ¬„ä½ï¼ˆå¦‚ summary/contentï¼‰å¯èƒ½æ˜¯ dict/listï¼Œ
    åœ¨åšåˆ‡ç‰‡å‰ä¸€å¾‹è½‰æˆå­—ä¸²é¿å… KeyError: slice(None, 1200, None)ã€‚
    """
    try:
        raw = yf.Ticker(symbol).news or []
    except Exception:
        raw = []

    items = []
    for n in raw[:max_items]:
        # å¯èƒ½æ˜¯ str / dict / list / None â†’ çµ±ä¸€è½‰æˆå­—ä¸²
        raw_summary = n.get("summary") if isinstance(n, dict) else ""
        raw_content = n.get("content") if isinstance(n, dict) else ""
        text_sum = to_text(raw_summary) or to_text(raw_content) or ""
        text_sum = text_sum[:NEWS_ITEM_MAX_CHARS]  # ç¾åœ¨ä¸€å®šæ˜¯å­—ä¸²ï¼Œå®‰å…¨åˆ‡ç‰‡

        items.append({
            "title": (n.get("title") or "") if isinstance(n, dict) else "",
            "link": (n.get("link") or n.get("url") or "") if isinstance(n, dict) else "",
            "publisher": (n.get("publisher") or "Yahoo Finance") if isinstance(n, dict) else "Yahoo Finance",
            "published_ts": int(n.get("providerPublishTime", 0)) if isinstance(n, dict) and n.get("providerPublishTime") else None,
            "published_at_fmt": _epoch_to_local_str(n.get("providerPublishTime")) if isinstance(n, dict) and n.get("providerPublishTime") else "",
            "content": text_sum,
            "source": "Yahoo"
        })
    return items

# --- Google News RSSï¼ˆå¯æŒ‡å®šç«™å°ï¼‰ ---
def _parse_google_news_rss(query: str, site: str | None, max_items: int = 3):
    q = quote_plus(query + (f" site:{site}" if site else ""))
    url = f"https://news.google.com/rss/search?q={q}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    try:
        r = requests.get(url, timeout=8)
        r.raise_for_status()
    except Exception:
        return []
    try:
        root = ET.fromstring(r.text)
    except Exception:
        return []
    ns = {}
    items = []
    for item in root.findall(".//item", ns)[:max_items]:
        title = (item.findtext("title") or "").strip()
        link  = (item.findtext("link") or "").strip()
        pub   = (item.findtext("pubDate") or "").strip()
        src   = ""
        src_el = item.find("{*}source")
        if src_el is not None and src_el.text:
            src = src_el.text.strip()
        items.append({
            "title": title, "link": link,
            "publisher": src or (site or "Google News"),
            "published_ts": None, "published_at_fmt": _fmt_dt_str(pub),
            "content": "", "source": site or "GoogleNews"
        })
    return items

@st.cache_data(show_spinner=False, ttl=600)
def fetch_news_multi(symbol: str, display_name: str, each: int = 3):
    """ä¸‰å€‹ç¶²ç«™ï¼šYahoo + GoogleNews(UDN) + GoogleNews(CNYES)ï¼Œå„å– 3 å‰‡"""
    q = display_name or symbol
    lst = []
    lst += fetch_news_yahoo(symbol, max_items=each)
    lst += _parse_google_news_rss(q, site="money.udn.com", max_items=each)
    lst += _parse_google_news_rss(q, site="news.cnyes.com", max_items=each)
    for it in lst:
        if not it.get("content"):
            it["content"] = it.get("title","")
    return lst[: (each*3)]

def classify_news_with_gemini(symbol: str, news_items: list, temperature: float):
    if not news_items: return []
    fallback = (
        "ä½ æ˜¯é‡‘èæ–‡æœ¬æ¨™è¨»å“¡ã€‚åƒ…ä¾æä¾›çš„æ¸…å–®å°æ¯å‰‡è¼¸å‡º JSONï¼Œä¸è¦å¤šé¤˜èªªæ˜ã€‚\n"
        "æ¯å‰‡è¼¸å‡ºæ¬„ä½ï¼štitle, published_at, link, summary,\n"
        "stock_sentiment:{label:[Bullish,Bearish,Neutral],score:0~1}, "
        "article_sentiment:{label:[Positive,Negative,Neutral],score:0~1}, relevance:0~1ã€‚\n"
        "è«‹åªè¼¸å‡º JSONã€‚"
    )
    tpl = load_prompt("news_classify_prompt.txt", fallback)
    prompt = f"{tpl}\n\n[è¼¸å…¥è³‡æ–™]\nè‚¡ç¥¨: {symbol}\næ–°èæ¸…å–®(JSON):\n{json.dumps(news_items, ensure_ascii=False, indent=2)}"
    try:
        cfg = types.GenerateContentConfig(temperature=temperature)
        resp = client.models.generate_content(model=GEMINI_MODEL, contents=[prompt], config=cfg)
        parsed = extract_json_block(resp.text or "")
        if isinstance(parsed, list): return parsed
    except Exception:
        pass
    # fallbackï¼šè‹¥ LLM å¤±æ•—å‰‡ä»¥ä¸­æ€§å¡«å›
    return [{
        "title": it.get("title",""), "published_at": it.get("published_at_fmt",""), "link": it.get("link",""),
        "summary": (it.get("content","") or "")[:200],
        "stock_sentiment": {"label":"Neutral","score":0.5},
        "article_sentiment": {"label":"Neutral","score":0.5},
        "relevance": 0.5
    } for it in (news_items or [])]

def build_overall_report(symbol: str, features: dict, results: list, temperature: float):
    """ç”¢ç”Ÿå®Œæ•´ Markdown å ±å‘Šï¼ˆå«ï¼šå¸‚å ´æƒ…ç·’ç¸½çµ / AI åˆ†æçµæœï¼‰"""
    fallback = (
        "ä½ æ˜¯åš´è¬¹çš„æŠ•è³‡ç ”ç©¶åŠ©ç†ã€‚ä»¥æ¢åˆ—è¼¸å‡ºï¼Œä¸è¦æŠ•è³‡å»ºè­°ï¼›"
        "å¿…è¦æ™‚ç”¨ã€è‹¥Aå‰‡Bã€æ¢ä»¶åŒ–èªå¥ã€‚\n"
        "è«‹ä¾æ“šä¸‹æ–¹ JSON è¼¸å‡ºç« ç¯€ï¼š\n"
        "## å¸‚å ´æƒ…ç·’ç¸½çµ\n"
        "## AI åˆ†æçµæœ\n"
        "### åˆ†æç¸½çµ\n"
        "### åª’é«”æƒ…ç·’è§€å¯Ÿ\n"
        "### æ¢ä»¶åŒ–æƒ…å¢ƒèˆ‡åƒ¹ä½å¸¶"
    )
    tpl = load_prompt("final_report_prompt.txt", fallback)

    counts = {"Bullish":0,"Neutral":0,"Bearish":0}; rel = 0.0
    for r in (results or []):
        lab = r.get("stock_sentiment",{}).get("label","Neutral")
        counts[lab] = counts.get(lab,0) + 1
        rel += float(r.get("relevance",0.0) or 0.0)
    total = len(results); avg_rel = round(rel/total, 3) if total else 0.0

    payload = {
        "symbol": symbol,
        "features": features,
        "sentiment_stats": {
            "total": total,
            "bullish": counts["Bullish"],
            "neutral": counts["Neutral"],
            "bearish": counts["Bearish"],
            "avg_relevance": avg_rel
        },
        "top_news": [{
            "title": r.get("title",""),
            "sentiment": r.get("stock_sentiment",{}).get("label","Neutral"),
            "relevance": r.get("relevance", 0.0),
            "summary": to_text(r.get("summary",""))
        } for r in (results or [])[:5]]
    }
    prompt = f"{tpl}\n\n[è¼¸å…¥è³‡æ–™]\n{json.dumps(payload, ensure_ascii=False, indent=2)}"
    try:
        cfg = types.GenerateContentConfig(temperature=temperature)
        resp = client.models.generate_content(model=GEMINI_MODEL, contents=[prompt], config=cfg)
        return resp.text or ""
    except Exception as e:
        base = (
            f"## å¸‚å ´æƒ…ç·’ç¸½çµ\n"
            f"- è¿‘ {features['period_bars']} æ ¹æ¼²è·Œå¹…ï¼š{features['pct_change_period']}%\n"
            f"- å‡ç·šï¼šSMA20 èˆ‡ SMA60 ç‚ºã€Œ{features['ma_trend']}ã€çµæ§‹ï¼›"
            f"é»ƒé‡‘äº¤å‰ï¼š{features['golden_cross']}ï¼›æ­»äº¡äº¤å‰ï¼š{features['dead_cross']}\n"
            f"- RSI14ï¼š{features['rsi14']}ï¼ˆ{features['rsi_state']}ï¼‰ï¼›é‡èƒ½æ˜¯å¦æ”¾å¤§ï¼š"
            f"{'æ˜¯' if features['volume_spike'] else 'å¦'}ï¼ˆè¿‘ 30 æ—¥å‡é‡ç´„ {features['volume_mean_period']:,}ï¼‰\n"
            f"- æ”¯æ’å€ï¼š{features['support_near']}ï¼›å£“åŠ›å€ï¼š{features['resistance_near']}\n\n"
            f"## AI åˆ†æçµæœ\n"
            f"### åˆ†æç¸½çµ\n- è³‡æ–™ä¸è¶³ä»¥ç”Ÿæˆå®Œæ•´ AI å ±å‘Šï¼ˆ{e}ï¼‰ã€‚\n"
        )
        return base

def split_ai_report(text: str) -> tuple[str, str]:
    """æŠŠå®Œæ•´ Markdown æ‹†æˆã€å¸‚å ´æƒ…ç·’ç¸½çµã€èˆ‡ã€AI åˆ†æçµæœã€å…©æ®µï¼Œä¾¿æ–¼åˆ†å€é¡¯ç¤ºã€‚"""
    if not text: return "", ""
    m = re.search(r"^##\s*AI\s*åˆ†æçµæœ.*$", text, flags=re.M)
    if not m:
        return text.strip(), ""
    part1 = text[:m.start()]
    part2 = text[m.start():]
    part1 = re.sub(r"^##\s*[^\n]+\n?", "", part1.strip(), count=1, flags=re.M)
    part2 = re.sub(r"^##\s*[^\n]+\n?", "", part2.strip(), count=1, flags=re.M)
    return part1.strip(), part2.strip()

def make_report_download(name: str, text: str):
    st.download_button("â¬‡ï¸ ä¸‹è¼‰ Markdown å ±å‘Š", data=io.BytesIO(text.encode("utf-8")), file_name=name, mime="text/markdown")

# ====== Sidebarï¼šç²¾ç°¡æ§åˆ¶ï¼ˆæ–°èå›ºå®šé–‹å•Ÿï¼‰ ======
with st.sidebar:
    st.markdown("**åŸºæœ¬è¨­å®š**")
    st.caption("å¸‚å ´å›ºå®šï¼šå°è‚¡ï¼ˆ.TW / .TWOï¼‰")
    query = st.text_input("è¼¸å…¥åç¨±æˆ–ä»£ç¢¼ï¼ˆæ”¯æ´æ¨¡ç³Šï¼‰", value="2330")

    yahoo_found = yahoo_search_tw(query, 20)
    numeric_candidates = _resolve_numeric_code_candidates(query)

    direct = []
    if re.fullmatch(r"\d{1,6}\.(?:TW|TWO)", query.strip().upper()):
        sym = query.strip().upper()
        if _verify_symbol_has_data(sym):
            try:
                info = yf.Ticker(sym).info or {}
                nm = info.get("longName") or info.get("shortName") or ""
            except Exception:
                nm = ""
            direct.append({"symbol": sym, "name": nm})

    merged = []
    seen = set()
    for seq in (direct, numeric_candidates, yahoo_found):
        for it in seq:
            if it["symbol"] not in seen:
                merged.append(it); seen.add(it["symbol"])

    if not merged and re.fullmatch(r"\d{4}", query.strip()):
        merged.append({"symbol": f"{query.strip()}.TW", "name": ""})

    options = [f'{it["symbol"]} â€” {it["name"]}' if it["name"] else it["symbol"] for it in merged] or ["ï¼ˆç„¡çµæœï¼Œè«‹è¼¸å…¥å…¶ä»–é—œéµå­—ï¼‰"]
    sel = st.selectbox("æœå°‹çµæœ", options, index=0)
    if merged:
        sel_idx = options.index(sel); symbol = merged[sel_idx]["symbol"]; display_name = merged[sel_idx]["name"] or ""
    else:
        symbol, display_name = ("2330.TW", "")
    if not display_name: display_name = get_name_by_symbol(symbol)

    period   = DEFAULT_PERIOD
    interval = DEFAULT_INTERVAL
    lookback = DEFAULT_LOOKBACK

    st.markdown("---")
    st.markdown("**å¯¦é©—åŠŸèƒ½ï¼šåƒ¹æ ¼è·¯å¾‘é æ¸¬**")
    predict_enabled = st.toggle("é¡¯ç¤ºæœªä¾†ä¸€é€±é æ¸¬", value=True)
    forecast_steps = 5 if interval == "1d" else 1

    st.markdown("---")
    st.caption(f"AI Temperature å·²å›ºå®šç‚º {FIXED_TEMPERATURE}ï¼ˆè¼ƒè©³ç´°ã€è¼ƒä¸€è‡´ï¼‰")

    st.markdown("---")
    # æ–°èå›ºå®šé–‹å•Ÿï¼ˆç§»é™¤åˆ‡æ›éˆ•ï¼‰
    st.caption("è‡ªå‹•æŠ“å–æ–°èï¼šYahoo + UDN + é‰…äº¨ï¼ˆå·²å›ºå®šå•Ÿç”¨ï¼‰")
    max_each_site = 3

    st.markdown("---")
    disclaimer = st.checkbox("æˆ‘äº†è§£æœ¬å·¥å…·åƒ…ä¾›æ•™è‚²ç”¨é€”ï¼ŒéæŠ•è³‡å»ºè­°ã€‚", value=True)
    run_btn = st.button("ç”¢ç”Ÿåˆ†æ", use_container_width=True)

# ====== ä¸»æµç¨‹ ======
def run_analysis(params: dict):
    symbol        = params["symbol"]
    display_name  = params.get("display_name") or get_name_by_symbol(symbol)
    period        = params["period"]
    interval      = params["interval"]
    lookback      = params["lookback"]
    temperature   = params["temperature"]
    max_each_site = params["max_each_site"]
    disclaimer    = params["disclaimer"]
    predict_enabled = params.get("predict_enabled", False)
    forecast_steps  = int(params.get("forecast_steps", 5))

    if not disclaimer:
        st.warning("è«‹å‹¾é¸ã€åƒ…ä¾›æ•™è‚²ç”¨é€”ã€å¾Œå†åŸ·è¡Œã€‚"); st.stop()

    st.markdown(f"### {display_name}ï¼ˆ {symbol} ï¼‰" if display_name else f"### ï¼ˆ {symbol} ï¼‰")

    # === è³‡æ–™ & æŒ‡æ¨™ ===
    data = fetch_ohlcv(symbol, period, interval)
    if data.empty: st.warning("æŠ“ä¸åˆ°è³‡æ–™ï¼Œè«‹ç¢ºèªä»£ç¢¼æˆ–æœŸé–“è¨­å®šã€‚"); st.stop()
    df = compute_indicators(data)
    feats = summarize_features(df, lookback=lookback)

    # === ä¸€ã€è‚¡åƒ¹è¶¨å‹¢åœ– ===
    st.markdown('<a id="sec-chart"></a>', unsafe_allow_html=True)
    st.markdown("## ä¸€ã€è‚¡åƒ¹è¶¨å‹¢åœ–")
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.03, row_heights=[0.7, 0.3])

    fig.add_trace(go.Candlestick(
        x=df.index, open=df["Open"], high=df["High"], low=df["Low"], close=df["Close"], name="K",
        increasing=dict(line=dict(color="#26A69A", width=1.2), fillcolor="rgba(38,166,154,0.6)"),
        decreasing=dict(line=dict(color="#EF5350", width=1.2), fillcolor="rgba(239,83,80,0.6)")
    ), row=1, col=1)

    fig.add_trace(go.Scatter(x=df.index, y=df["SMA20"], name="SMA20", mode="lines",
                             line=dict(width=2.2, color="#60A5FA")), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index, y=df["SMA60"], name="SMA60", mode="lines",
                             line=dict(width=2.2, color="#F9A8D4")), row=1, col=1)

    s20, s60 = df["SMA20"], df["SMA60"]
    cross_up_idx = (s20.shift(1) <= s60.shift(1)) & (s20 > s60)
    cross_dn_idx = (s20.shift(1) >= s60.shift(1)) & (s20 < s60)
    fig.add_trace(go.Scatter(x=df.index[cross_up_idx], y=df.loc[cross_up_idx, "Close"], mode="markers",
                             name="é»ƒé‡‘äº¤å‰", marker_symbol="triangle-up", marker_size=10, marker_color="#22c55e"), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index[cross_dn_idx], y=df.loc[cross_dn_idx, "Close"], mode="markers",
                             name="æ­»äº¡äº¤å‰", marker_symbol="triangle-down", marker_size=10, marker_color="#f97316"), row=1, col=1)

    if feats["support_near"]:
        fig.add_shape(type="line", x0=df.index[0], x1=df.index[-1], y0=feats["support_near"], y1=feats["support_near"],
                      xref="x", yref="y", line=dict(dash="dot", width=1.6, color="#10b981"), row=1, col=1)
    if feats["resistance_near"]:
        fig.add_shape(type="line", x0=df.index[0], x1=df.index[-1], y0=feats["resistance_near"], y1=feats["resistance_near"],
                      xref="x", yref="y", line=dict(dash="dot", width=1.6, color="#ef4444"), row=1, col=1)

    fig.add_trace(go.Bar(x=df.index, y=df["Volume"], name="Volume", marker_color="rgba(100,116,139,0.7)"), row=2, col=1)

    if predict_enabled and forecast_steps > 0:
        try:
            base = df[["Open","High","Low","Close"]].dropna()
            fdf, med, p10, p90 = forecast_ohlc(base, steps=forecast_steps, interval=interval)
            purple = "#A855F7"
            fig.add_vrect(x0=df.index[-1], x1=fdf.index[-1], fillcolor="rgba(168,85,247,0.08)", line_width=0, row=1, col=1)
            fig.add_trace(go.Candlestick(
                x=fdf.index, open=fdf["Open"], high=fdf["High"], low=fdf["Low"], close=fdf["Close"], name="é æ¸¬K",
                increasing=dict(line=dict(color=purple, width=1.2), fillcolor="rgba(168,85,247,0.45)"),
                decreasing=dict(line=dict(color=purple, width=1.2), fillcolor="rgba(168,85,247,0.45)"),
                opacity=0.85, whiskerwidth=0.3
            ), row=1, col=1)
            fig.add_trace(go.Scatter(x=med.index, y=p90, name="P90(æ”¶ç›¤)", mode="lines",
                                     line=dict(width=1.2, dash="dashdot", color=purple)), row=1, col=1)
            fig.add_trace(go.Scatter(x=med.index, y=p10, name="P10(æ”¶ç›¤)", mode="lines",
                                     line=dict(width=1.2, dash="dot", color=purple),
                                     fill="tonexty", fillcolor="rgba(168,85,247,0.12)"), row=1, col=1)
            fig.add_trace(go.Scatter(x=med.index, y=med, name="é æ¸¬æ”¶ç›¤(ä¸­ä½)", mode="lines+markers",
                                     line=dict(width=2.2, dash="dash", color=purple),
                                     marker=dict(size=5, symbol="diamond")), row=1, col=1)
            fig.update_xaxes(range=[df.index[0], fdf.index[-1] + pd.Timedelta(days=2)])
        except Exception as e:
            st.info(f"ï¼ˆé æ¸¬å±¤è¼‰å…¥å¤±æ•—ï¼š{e}ï¼‰")

    fig.update_layout(template="plotly_dark", xaxis_rangeslider_visible=False, height=620,
                      margin=dict(l=10, r=60, t=36, b=10),
                      legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                      hovermode="x unified")
    st.plotly_chart(fig, use_container_width=True)

    # KPI
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("æœ€æ–°æ”¶ç›¤", feats["close_last"])
    c2.metric("è¿‘Næ ¹æ¼²è·Œå¹…(%)", feats["pct_change_period"])
    c3.metric("æ”¯æ’å€(Fib 0.618)", _s(feats["support_near"]))
    c4.metric("å£“åŠ›å€(Fib 0.382)", _s(feats["resistance_near"]))

    c5, c6, c7, c8 = st.columns(4)
    c5.metric("RSI14", _s(feats["rsi14"]))
    c6.metric("é‡èƒ½æ˜¯å¦æ”¾å¤§", "æ˜¯" if feats["volume_spike"] else "å¦",
              help=f"æœ€æ–°ä¸€æ ¹ vs è¿‘ {VOLUME_LOOKBACK} æ ¹å‡é‡ï¼›â‰¥ {VOL_SPIKE_MULTIPLIER} å€è¦–ç‚ºæ”¾å¤§")
    c7.metric("é‡èƒ½åŸºæº–(è¿‘30æ—¥)", f"{feats['volume_mean_period']:,}")
    c8.metric("æœ€æ–°é‡", f"{feats['volume_last']:,}")

    # === æŠ€è¡“è¼”åŠ©æŒ‡æ¨™ï¼ˆKD / MACDï¼‰ ===
    st.markdown('<a id="sec-tech"></a>', unsafe_allow_html=True)
    st.markdown("### æŠ€è¡“è¼”åŠ©æŒ‡æ¨™")
    col_a, col_b = st.columns(2)
    fig_kd = go.Figure()
    fig_kd.add_trace(go.Scatter(x=df.index, y=df["KD_K"], mode="lines", name="%K(9)"))
    fig_kd.add_trace(go.Scatter(x=df.index, y=df["KD_D"], mode="lines", name="%D(3)"))
    fig_kd.add_hline(y=80, line_dash="dot"); fig_kd.add_hline(y=20, line_dash="dot")
    fig_kd.update_layout(template="plotly_dark", height=320, margin=dict(l=10, r=10, t=10, b=10), legend=dict(orientation="h"))
    with col_a: st.plotly_chart(fig_kd, use_container_width=True)

    fig_macd = go.Figure()
    fig_macd.add_trace(go.Bar(x=df.index, y=df["MACD_hist"], name="Hist"))
    fig_macd.add_trace(go.Scatter(x=df.index, y=df["MACD"], mode="lines", name="MACD"))
    fig_macd.add_trace(go.Scatter(x=df.index, y=df["MACD_signal"], mode="lines", name="Signal"))
    fig_macd.update_layout(template="plotly_dark", height=320, margin=dict(l=10, r=10, t=10), legend=dict(orientation="h"))
    with col_b: st.plotly_chart(fig_macd, use_container_width=True)

    # === é»ƒé‡‘åˆ‡å‰²ç‡ï¼ˆåƒ…è¡¨æ ¼ï¼‰ ===
    st.markdown("### ğŸ“ é»ƒé‡‘åˆ‡å‰²ç‡é»ä½ï¼ˆÂ±0.382 / Â±0.618ï¼Œè¿‘ N æ ¹å¹…åº¦ï¼‰")
    fib_tbl = compute_fib_posneg(df, lookback)
    if fib_tbl is not None and not fib_tbl.empty:
        st.dataframe(fib_tbl, use_container_width=True, hide_index=True)
    else:
        st.info("ç„¡æ³•è¨ˆç®—é»ƒé‡‘åˆ‡å‰²ç‡ï¼ˆè³‡æ–™ä¸è¶³ï¼‰ã€‚")

    # === äºŒã€æƒ…å ±æ–°èæ‘˜è¦ï¼ˆå›ºå®šå•Ÿç”¨ï¼‰ ===
    st.markdown('<a id="sec-news"></a>', unsafe_allow_html=True)
    st.markdown("## äºŒã€æƒ…å ±æ–°èæ‘˜è¦")
    results = []
    items = []
    with st.spinner("æŠ“å–æ–°èä¸­â€¦"):
        items = fetch_news_multi(symbol, display_name, each=max_each_site)
    if items:
        with st.spinner("AI æƒ…ç·’åˆ†æä¸­â€¦"):
            results = classify_news_with_gemini(symbol, items, FIXED_TEMPERATURE)

        def _agg(res):
            if not res: return {"total":0,"bullish":0,"neutral":0,"bearish":0,"bullish_ratio":0.0,"avg_rel":0.0}
            m = {"Bullish":0,"Neutral":0,"Bearish":0}
            s_rel = 0.0
            for r in res:
                m[r.get("stock_sentiment",{}).get("label","Neutral")] += 1
                s_rel += float(r.get("relevance",0.0) or 0.0)
            t = len(res)
            return {"total":t,"bullish":m["Bullish"],"neutral":m["Neutral"],"bearish":m["Bearish"],
                    "bullish_ratio": round(m["Bullish"]/t,3), "avg_rel": round(s_rel/t,3)}
        agg = _agg(results)

        r1, r2, r3, r4 = st.columns([2,1,1,1])
        with r2: st.metric("æ–°èç¸½ç¯‡æ•¸", agg["total"])
        with r3: st.metric("æ­£å‘æ¯”ä¾‹", f'{int(agg["bullish_ratio"]*100)}%')
        with r4: st.metric("å¹³å‡ç›¸é—œæ€§", agg["avg_rel"])

        pos = int(agg["bullish_ratio"]*100)
        pie_df = pd.DataFrame({"label":["æ­£å‘(Bullish)","ä¸­ç«‹/è² å‘(others)"], "value":[pos, 100-pos]})
        st.plotly_chart(px.pie(pie_df, names="label", values="value", hole=0.55, title="æƒ…ç·’çµ±è¨ˆçµæœ")
                        .update_layout(template="plotly_dark", margin=dict(l=0,r=0,t=40,b=0), height=300),
                        use_container_width=True)

        st.markdown("### ğŸ§¾ è©³ç´°æ–°èåˆ—è¡¨")
        for i, r in enumerate(results):
            meta = items[i] if i < len(items) else {}
            src = meta.get("publisher","")
            pub = meta.get("published_at_fmt","") or r.get("published_at","")
            stock_lab = r.get("stock_sentiment",{}).get("label","Neutral")
            art_lab   = r.get("article_sentiment",{}).get("label","Neutral")
            stock_badge = "badge-green" if stock_lab=="Bullish" else ("badge-red" if stock_lab=="Bearish" else "badge-gray")
            art_badge   = "badge-green" if art_lab=="Positive" else ("badge-red" if art_lab=="Negative" else "badge-gray")
            title = _s(r.get("title","(ç„¡æ¨™é¡Œ)"))
            summary_txt = (_s(r.get('summary','')).strip())
            link_txt = _s(r.get('link','')).strip()
            link_html = f"<div style='margin-top:8px;'><a href=\"{link_txt}\" target=\"_blank\">æŸ¥çœ‹åŸæ–‡</a></div>" if link_txt else ""
            meta_line = f"æ¶ˆæ¯ä¾†æºï¼š{src or 'â€”'}ã€€|ã€€ç™¼ä½ˆæ™‚é–“ï¼š{pub or 'â€”'}ã€€|ã€€ç›¸é—œæ€§åˆ†æ•¸ï¼š{_s(r.get('relevance',0))}"
            st.markdown(
                f"""
<div class="card">
  <div class="small" style="margin:6px 0;">{meta_line}</div>
  <div style="font-weight:600">{title}</div>
  <div style="margin:6px 0;">
    <span class="badge {stock_badge}">ğŸ“ˆ è‚¡ç¥¨æƒ…ç·’ï¼š{stock_lab}</span>
    <span class="badge {art_badge}">ğŸ“° æ–‡ç« æƒ…ç·’ï¼š{art_lab}</span>
  </div>
  <div style="white-space:pre-wrap; margin-top:6px;">{summary_txt}</div>
  {link_html}
</div>
                """,
                unsafe_allow_html=True,
            )
    else:
        st.info("ç›®å‰æŠ“ä¸åˆ°æ–°èï¼Œå·²è·³éæƒ…ç·’åˆ†æã€‚")

    # === ä¸‰ï¼šAI å ±å‘Šï¼ˆåƒ…é¡¯ç¤ºã€ŒAI åˆ†æçµæœã€ç« ç¯€ï¼‰ ===
    st.markdown('<a id="sec-ai"></a>', unsafe_allow_html=True)
    st.markdown("## ä¸‰ã€AI åˆ†æçµæœ")
    st.caption("â€» æœ¬å·¥å…·ç‚ºæ•™è‚²ç”¨é€”çš„åˆ†æè¼”åŠ©ï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ã€‚")

    with st.spinner("AI å ±å‘Šç”Ÿæˆä¸­â€¦"):
        full_md = build_overall_report(symbol, feats, results, FIXED_TEMPERATURE)
        part_summary, part_ai = split_ai_report(full_md)

    # åªé¡¯ç¤º AI ç« ç¯€ï¼›è‹¥æ¨¡å‹æœªè¼¸å‡ºæ‹†æ®µï¼Œå‰‡é¡¯ç¤ºå®Œæ•´å…§å®¹ä½œç‚ºä¿åº•
    if part_ai:
        st.markdown(part_ai)
    else:
        st.markdown(re.sub(r"^##\s*[^\n]+\n?", "", (full_md or "").strip(), count=1, flags=re.M))

    # å ±å‘Šä¸‹è¼‰ï¼ˆMarkdownï¼‰
    today = dt.datetime.now().strftime("%Y%m%d")
    report_name = f"{symbol.replace('.','_')}_report_{today}.md"
    make_report_download(report_name, full_md)

# ====== äº‹ä»¶è™•ç† ======
if run_btn:
    st.session_state.last_params = {
        "symbol": symbol, "display_name": display_name,
        "period": DEFAULT_PERIOD, "interval": DEFAULT_INTERVAL, "lookback": DEFAULT_LOOKBACK,
        "temperature": FIXED_TEMPERATURE, "max_each_site": max_each_site,
        "disclaimer": True, "predict_enabled": predict_enabled, "forecast_steps": forecast_steps
    }
    run_analysis(st.session_state.last_params)
elif st.session_state.last_params:
    run_analysis(st.session_state.last_params)
